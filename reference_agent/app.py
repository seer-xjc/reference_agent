import os
import gradio as gr
from pathlib import Path
import tempfile
from collections import Counter
from docx import Document
import fitz
from dotenv import load_dotenv
from zhipuai import ZhipuAI
from utils import (
    get_reference_titles,
    get_citation_markers,
    search_from_arxiv,
    get_arxiv_metadata_only,
    batch_verify_citations_lightweight,
    load_pdf,
    load_prompt
)
from difflib import SequenceMatcher
import time

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def clean_title_for_comparison(title):
    """æ¸…ç†æ ‡é¢˜ç”¨äºæ¯”è¾ƒï¼Œå»é™¤æ ‡ç‚¹ç¬¦å·ã€è½¬æ¢ä¸ºå°å†™ç­‰"""
    import re
    cleaned = re.sub(r'[^\w\s]', ' ', title.lower())
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned

def is_similar(title1, title2, threshold=0.8):
    """æ”¹è¿›çš„ç›¸ä¼¼æ€§æ¯”è¾ƒå‡½æ•°"""
    similarity1 = SequenceMatcher(None, title1.lower(), title2.lower()).ratio()
    
    clean_title1 = clean_title_for_comparison(title1)
    clean_title2 = clean_title_for_comparison(title2)
    similarity2 = SequenceMatcher(None, clean_title1, clean_title2).ratio()
    
    words1 = set(clean_title1.split())
    words2 = set(clean_title2.split())
    if len(words1) > 0 and len(words2) > 0:
        word_overlap = len(words1.intersection(words2)) / len(words1.union(words2))
    else:
        word_overlap = 0
    
    max_similarity = max(similarity1, similarity2, word_overlap)
    return max_similarity > threshold, max_similarity

def load_document(file_path):
    """æ”¯æŒåŠ è½½word/pdfæ–‡æ¡£"""
    if file_path.endswith('.pdf'):
        with fitz.open(file_path) as doc:
            return "\n".join([page.get_text() for page in doc])
    else:
        return "\n".join([p.text for p in Document(file_path).paragraphs if p.text])

def verify_citations_and_analyze_with_logs(file_path, lightweight_mode, skip_download, pdf_verify):
    """ä¸»è¦çš„æ–‡çŒ®æ£€æŸ¥å‡½æ•°ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½ï¼Œå¸¦å®æ—¶æ—¥å¿—"""
    
    # å­˜å‚¨ç»“æœçš„å­—å…¸
    results = {
        'doc_content': '',
        'titles': [],
        'citations_info': {},
        'arxiv_found': [],
        'arxiv_not_found': [],
        'verification_results': []
    }
    
    log_messages = []
    
    def add_log(message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        log_messages.append(f"[{time.strftime('%H:%M:%S')}] {message}")
        return "\n".join(log_messages)
    
    try:
        # åˆå§‹åŒ–æ—¥å¿—
        yield add_log("ğŸš€ å¼€å§‹æ–‡çŒ®æ£€æŸ¥åˆ†æ..."), "", "", "", "", "åˆ†æä¸­..."
        
        # 1. åŠ è½½æ–‡æ¡£
        add_log(f"ğŸ“– æ­£åœ¨åŠ è½½æ–‡æ¡£: {Path(file_path).name}")
        doc_content = load_document(file_path)
        results['doc_content'] = doc_content
        add_log(f"âœ… æ–‡æ¡£åŠ è½½å®Œæˆï¼Œå…± {len(doc_content)} ä¸ªå­—ç¬¦")
        yield add_log(""), "", "", "", "", "åˆ†æä¸­..."
        
        # 2. æå–å‚è€ƒæ–‡çŒ®æ ‡é¢˜
        add_log("ğŸ” æ­£åœ¨æå–å‚è€ƒæ–‡çŒ®æ ‡é¢˜...")
        titles = get_reference_titles(doc_content)
        results['titles'] = titles
        add_log(f"ğŸ“š æå–åˆ° {len(titles)} ç¯‡å‚è€ƒæ–‡çŒ®")
        yield add_log(""), "", "", "", "", "åˆ†æä¸­..."
        
        # 3. åˆ†æå¼•æ–‡æ•°é‡å’Œå¼•ç”¨æƒ…å†µ
        add_log("ğŸ“Š æ­£åœ¨åˆ†æå¼•æ–‡æ ‡è®°...")
        citations_to_text = get_citation_markers(doc_content)
        add_log(f"ğŸ”– æ‰¾åˆ° {len(citations_to_text)} ä¸ªå¼•ç”¨æ ‡è®°")
        
        citations = []
        for citation, citation_text in citations_to_text:
            citations.extend(citation)
        
        # ç»Ÿè®¡æœªè¢«å¼•ç”¨çš„æ–‡çŒ®
        missed_citations = list(set(range(1, len(titles)+1)) - set(citations))
        
        # ç»Ÿè®¡é‡å¤å¼•ç”¨
        counter = Counter(citations)
        duplicate_citations = [citation for citation, count in counter.items() if count > 1]
        
        results['citations_info'] = {
            'total_references': len(titles),
            'total_citations': len(citations_to_text),
            'unique_citations': len(set(citations)),
            'missed_citations': missed_citations,
            'duplicate_citations': duplicate_citations,
            'citation_details': [(citation, count) for citation, count in counter.items() if count > 1]
        }
        
        # æ—¥å¿—è¾“å‡ºç»Ÿè®¡ç»“æœ
        add_log(f"ğŸ“ˆ å¼•æ–‡ç»Ÿè®¡å®Œæˆ:")
        add_log(f"   - æ€»å¼•ç”¨æ•°: {len(set(citations))} ä¸ª")
        add_log(f"   - æœªå¼•ç”¨æ–‡çŒ®: {len(missed_citations)} ç¯‡")
        add_log(f"   - é‡å¤å¼•ç”¨: {len(duplicate_citations)} ç¯‡")
        
        # è¾“å‡ºå¼•æ–‡åˆ†æç»“æœ
        citation_analysis = format_citation_analysis(results)
        yield add_log(""), citation_analysis, "", "", "", "åˆ†æä¸­..."
        
        # 4. åœ¨arXivä¸­æœç´¢æ–‡çŒ®
        add_log("ğŸŒ å¼€å§‹åœ¨arXivä¸­æœç´¢æ–‡çŒ®...")
        arxiv_found = []
        arxiv_not_found = []
        
        for i, title in enumerate(titles):
            add_log(f"ğŸ“„ å¤„ç†æ–‡çŒ® {i+1}/{len(titles)}: {title[:50]}{'...' if len(title) > 50 else ''}")
            yield add_log(""), citation_analysis, "", "", "", f"æ­£åœ¨æœç´¢æ–‡çŒ® {i+1}/{len(titles)}..."
            
            try:
                add_log(f"ğŸ” åœ¨arXivæœç´¢: {title[:30]}...")
                search_results = list(search_from_arxiv(title))
                found_match = False
                
                if search_results:
                    add_log(f"   ğŸ“š æ‰¾åˆ° {len(search_results)} ä¸ªæœç´¢ç»“æœ")
                    
                    for j, result in enumerate(search_results):
                        add_log(f"   ğŸ” æ£€æŸ¥ç»“æœ {j+1}: {result.title[:40]}...")
                        is_match, similarity = is_similar(result.title, title)
                        add_log(f"      ç›¸ä¼¼åº¦: {similarity:.3f}")
                        
                        if is_match:
                            add_log(f"   âœ… æ‰¾åˆ°åŒ¹é…! ç›¸ä¼¼åº¦: {similarity:.3f}")
                            arxiv_found.append({
                                'index': i + 1,
                                'title': title,
                                'arxiv_title': result.title,
                                'similarity': similarity,
                                'authors': [str(author) for author in result.authors],
                                'abstract': result.summary[:200] + "..." if len(result.summary) > 200 else result.summary
                            })
                            found_match = True
                            break
                        else:
                            add_log(f"      âŒ ç›¸ä¼¼åº¦ä¸è¶³ (é˜ˆå€¼: 0.6)")
                
                if not found_match:
                    add_log(f"   âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡çŒ®")
                    arxiv_not_found.append({
                        'index': i + 1,
                        'title': title
                    })
                    
            except Exception as e:
                add_log(f"   âŒ æœç´¢å‡ºé”™: {str(e)[:50]}...")
                arxiv_not_found.append({
                    'index': i + 1,
                    'title': title,
                    'error': str(e)
                })
            
            # æ¯å¤„ç†5ç¯‡æ–‡çŒ®æ›´æ–°ä¸€æ¬¡ç•Œé¢
            if (i + 1) % 5 == 0 or i == len(titles) - 1:
                results['arxiv_found'] = arxiv_found
                results['arxiv_not_found'] = arxiv_not_found
                arxiv_found_text, arxiv_not_found_text = format_arxiv_analysis(results)
                yield add_log(""), citation_analysis, arxiv_found_text, arxiv_not_found_text, "", f"å·²å¤„ç† {i+1}/{len(titles)} ç¯‡æ–‡çŒ®"
        
        results['arxiv_found'] = arxiv_found
        results['arxiv_not_found'] = arxiv_not_found
        
        add_log(f"ğŸ“Š arXivæœç´¢å®Œæˆ:")
        add_log(f"   - æ‰¾åˆ°åŒ¹é…: {len(arxiv_found)} ç¯‡")
        add_log(f"   - æœªæ‰¾åˆ°: {len(arxiv_not_found)} ç¯‡")
        
        # 5. AIç›¸å…³æ€§éªŒè¯ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
        add_log("ğŸ¤– å¼€å§‹AIç›¸å…³æ€§éªŒè¯...")
        if lightweight_mode:
            add_log("   ä½¿ç”¨è½»é‡çº§æ¨¡å¼: arXivå…ƒæ•°æ®éªŒè¯")
        else:
            add_log("   ä½¿ç”¨æ ‡å‡†æ¨¡å¼: PDFå†…å®¹éªŒè¯")
        
        yield add_log(""), citation_analysis, format_arxiv_analysis(results)[0], format_arxiv_analysis(results)[1], "", "æ­£åœ¨è¿›è¡ŒAIéªŒè¯..."
        
        add_log(f"   æ­£åœ¨éªŒè¯ {len(citations_to_text)} ä¸ªå¼•ç”¨æ ‡è®°...")
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©éªŒè¯æ–¹æ³•
        verification_results = []
        
        if lightweight_mode:
            # è½»é‡çº§æ¨¡å¼ï¼šä½¿ç”¨arXivå…ƒæ•°æ®
            for i, (citation, text) in enumerate(citations_to_text):
                add_log(f"   ğŸ” éªŒè¯å¼•ç”¨ {i+1}/{len(citations_to_text)}: {citation}")
                
                single_verification = batch_verify_citations_lightweight([(citation, text)], titles, "glm-4-flash")
                verification_results.extend(single_verification)
                
                if single_verification and single_verification[0]['status'] == 'verified':
                    result_text = single_verification[0].get('result', '')
                    if '<æ˜¯>' in result_text:
                        add_log(f"      âœ… éªŒè¯é€šè¿‡")
                    elif 'å¦' in result_text:
                        reason = result_text.replace('<å¦:', '').replace('>', '').strip()
                        add_log(f"      âŒ éœ€è¦æ£€æŸ¥: {reason[:50]}...")
                    else:
                        add_log(f"      âš ï¸  ç»“æœä¸æ˜ç¡®")
                else:
                    add_log(f"      â­ï¸  è·³è¿‡éªŒè¯")
                
                # æ¯éªŒè¯3ä¸ªå¼•ç”¨æ›´æ–°ä¸€æ¬¡ç•Œé¢
                if (i + 1) % 3 == 0 or i == len(citations_to_text) - 1:
                    yield add_log(""), citation_analysis, format_arxiv_analysis(results)[0], format_arxiv_analysis(results)[1], "", f"å·²éªŒè¯ {i+1}/{len(citations_to_text)} ä¸ªå¼•ç”¨"
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šä½¿ç”¨PDFå†…å®¹éªŒè¯
            ref_dir = Path("../data/references")
            ref_names = [int(file.stem) for file in ref_dir.iterdir() if file.is_file() and file.suffix == '.pdf']
            add_log(f"   ğŸ“ å¼•ç”¨æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {len(ref_names)} ä¸ªPDFæ–‡ä»¶")
            
            for i, (citation, text) in enumerate(citations_to_text):
                add_log(f"   ğŸ” éªŒè¯å¼•ç”¨ {i+1}/{len(citations_to_text)}: {citation}")
                
                # æ£€æŸ¥å¼•ç”¨çš„æ–‡çŒ®æ˜¯å¦éƒ½æœ‰å¯¹åº”çš„PDFæ–‡ä»¶
                missing_refs = set(citation) - set(ref_names)
                if missing_refs:
                    add_log(f"      â­ï¸  è·³è¿‡ï¼ŒPDFæ–‡ä»¶ç¼ºå¤±: {sorted(missing_refs)}")
                    verification_results.append({
                        'citation': citation,
                        'status': 'skipped',
                        'reason': f'PDFæ–‡ä»¶ç¼ºå¤±: {sorted(missing_refs)}'
                    })
                    continue
                
                try:
                    # æ„å»ºPDFæ–‡ä»¶è·¯å¾„å¹¶åŠ è½½å†…å®¹
                    reference_paths = [ref_dir / f"{index}.pdf" for index in citation]
                    add_log(f"      ğŸ“– åŠ è½½PDF: {[f'{index}.pdf' for index in citation]}")
                    
                    references = load_pdf(reference_paths)
                    
                    if not references.strip():
                        add_log(f"      âš ï¸  PDFå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                        verification_results.append({
                            'citation': citation,
                            'status': 'skipped',
                            'reason': 'PDFå†…å®¹ä¸ºç©º'
                        })
                        continue
                    
                    # ä½¿ç”¨PDFå†…å®¹è¿›è¡ŒéªŒè¯
                    prompt_template = load_prompt("prompts/agent_prompt")
                    prompt = prompt_template.format(text, references)
                    
                    client = ZhipuAI(api_key=os.environ["ZHIPUAI_API_KEY"])
                    response = client.chat.completions.create(
                        model="glm-4-flash",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0
                    )
                    
                    result = response.choices[0].message.content
                    
                    verification_results.append({
                        'citation': citation,
                        'status': 'verified',
                        'result': result
                    })
                    
                    if '<æ˜¯>' in result:
                        add_log(f"      âœ… éªŒè¯é€šè¿‡")
                    elif 'å¦' in result:
                        reason = result.replace('<å¦:', '').replace('>', '').strip()
                        add_log(f"      âŒ éœ€è¦æ£€æŸ¥: {reason[:50]}...")
                    else:
                        add_log(f"      âš ï¸  ç»“æœä¸æ˜ç¡®: {result[:30]}...")
                        
                except Exception as e:
                    add_log(f"      âŒ éªŒè¯å‡ºé”™: {str(e)[:50]}...")
                    verification_results.append({
                        'citation': citation,
                        'status': 'error',
                        'reason': str(e)
                    })
                
                # æ¯éªŒè¯3ä¸ªå¼•ç”¨æ›´æ–°ä¸€æ¬¡ç•Œé¢
                if (i + 1) % 3 == 0 or i == len(citations_to_text) - 1:
                    yield add_log(""), citation_analysis, format_arxiv_analysis(results)[0], format_arxiv_analysis(results)[1], "", f"å·²éªŒè¯ {i+1}/{len(citations_to_text)} ä¸ªå¼•ç”¨"
        
        results['verification_results'] = verification_results
        
        # ç»Ÿè®¡éªŒè¯ç»“æœ
        verified_count = sum(1 for r in verification_results if r['status'] == 'verified')
        correct_count = sum(1 for r in verification_results if r['status'] == 'verified' and '<æ˜¯>' in r.get('result', ''))
        incorrect_count = sum(1 for r in verification_results if r['status'] == 'verified' and 'å¦' in r.get('result', ''))
        skipped_count = sum(1 for r in verification_results if r['status'] == 'skipped')
        error_count = sum(1 for r in verification_results if r['status'] == 'error')
        
        add_log(f"ğŸ¯ AIéªŒè¯å®Œæˆ:")
        add_log(f"   - å·²éªŒè¯: {verified_count} ä¸ªå¼•ç”¨")
        add_log(f"   - æŸ¥éªŒæ— è¯¯: {correct_count} ä¸ª")
        add_log(f"   - éœ€è¦æ£€æŸ¥: {incorrect_count} ä¸ª")
        add_log(f"   - è·³è¿‡: {skipped_count} ä¸ª")
        add_log(f"   - é”™è¯¯: {error_count} ä¸ª")
        
        if verified_count > 0:
            accuracy_rate = (correct_count / verified_count) * 100
            add_log(f"   - å‡†ç¡®ç‡: {accuracy_rate:.1f}%")
        
        # æœ€ç»ˆç»“æœ
        add_log("ğŸ‰ æ–‡çŒ®æ£€æŸ¥åˆ†æå®Œæˆ!")
        add_log("="*50)
        add_log("ğŸ“‹ åˆ†ææ€»ç»“:")
        add_log(f"   ğŸ“š å‚è€ƒæ–‡çŒ®: {len(titles)} ç¯‡")
        add_log(f"   ğŸ”– å¼•ç”¨æ ‡è®°: {len(citations_to_text)} ä¸ª") 
        add_log(f"   âœ… arXivæ‰¾åˆ°: {len(arxiv_found)} ç¯‡")
        add_log(f"   âŒ arXivæœªæ‰¾åˆ°: {len(arxiv_not_found)} ç¯‡")
        add_log(f"   ğŸ¤– AIéªŒè¯: {verified_count} ä¸ªå¼•ç”¨")
        
        # æ ¼å¼åŒ–æœ€ç»ˆç»“æœ
        citation_analysis = format_citation_analysis(results)
        arxiv_found_text, arxiv_not_found_text = format_arxiv_analysis(results)
        verified_correct, verified_incorrect = format_verification_results(results)
        
        yield add_log(""), citation_analysis, arxiv_found_text, arxiv_not_found_text, verified_correct, verified_incorrect, "âœ… åˆ†æå®Œæˆï¼"
        
    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {str(e)}"
        add_log(error_msg)
        yield add_log(""), error_msg, "", "", "", error_msg

def format_citation_analysis(results):
    """æ ¼å¼åŒ–å¼•æ–‡åˆ†æç»“æœ"""
    if 'error' in results:
        return f"âŒ é”™è¯¯: {results['error']}"
    
    info = results['citations_info']
    
    output = f"""ğŸ“Š **å¼•æ–‡åˆ†æç»“æœ**

**åŸºæœ¬ç»Ÿè®¡:**
- å‚è€ƒæ–‡çŒ®æ€»æ•°ï¼š{info['total_references']} ç¯‡
- å¼•ç”¨æ ‡è®°æ€»æ•°ï¼š{info['total_citations']} ä¸ª
- ä¸é‡å¤å¼•ç”¨æ•°ï¼š{info['unique_citations']} ä¸ª

**æœªè¢«å¼•ç”¨çš„æ–‡çŒ®ï¼š**"""
    
    if info['missed_citations']:
        output += f"\nâš ï¸ å…± {len(info['missed_citations'])} ç¯‡æ–‡çŒ®æœªè¢«å¼•ç”¨ï¼š"
        for citation in sorted(info['missed_citations']):
            output += f"\n   - æ–‡çŒ®[{citation}]: {results['titles'][citation-1] if citation <= len(results['titles']) else 'æ ‡é¢˜æœªçŸ¥'}"
    else:
        output += "\nâœ… æ‰€æœ‰æ–‡çŒ®éƒ½è¢«å¼•ç”¨äº†"
    
    output += "\n\n**é‡å¤å¼•ç”¨çš„æ–‡çŒ®ï¼š**"
    if info['duplicate_citations']:
        output += f"\nâš ï¸ å…± {len(info['duplicate_citations'])} ç¯‡æ–‡çŒ®è¢«é‡å¤å¼•ç”¨ï¼š"
        for citation, count in info['citation_details']:
            output += f"\n   - æ–‡çŒ®[{citation}]ï¼šè¢«å¼•ç”¨ {count} æ¬¡"
    else:
        output += "\nâœ… æ²¡æœ‰é‡å¤å¼•ç”¨çš„æ–‡çŒ®"
    
    return output

def format_arxiv_analysis(results):
    """æ ¼å¼åŒ–arXivåˆ†æç»“æœ"""
    if 'error' in results:
        return f"âŒ é”™è¯¯: {results['error']}", f"âŒ é”™è¯¯: {results['error']}"
    
    found_output = "ğŸ“š **arXivä¸­å¯ä»¥æ‰¾åˆ°çš„æ–‡çŒ®ï¼š**\n\n"
    if results['arxiv_found']:
        for item in results['arxiv_found']:
            found_output += f"**[{item['index']}]** {item['title']}\n"
            found_output += f"   - åŒ¹é…æ ‡é¢˜ï¼š{item['arxiv_title']}\n"
            found_output += f"   - ç›¸ä¼¼åº¦ï¼š{item['similarity']:.3f}\n"
            found_output += f"   - ä½œè€…ï¼š{', '.join(item['authors'][:3])}{'...' if len(item['authors']) > 3 else ''}\n\n"
    else:
        found_output += "âŒ æ²¡æœ‰åœ¨arXivä¸­æ‰¾åˆ°åŒ¹é…çš„æ–‡çŒ®"
    
    not_found_output = "ğŸ“š **arXivä¸­ä¸å¯ä»¥æ‰¾åˆ°çš„æ–‡çŒ®ï¼š**\n\n"
    if results['arxiv_not_found']:
        for item in results['arxiv_not_found']:
            not_found_output += f"**[{item['index']}]** {item['title']}\n"
            if 'error' in item:
                not_found_output += f"   - é”™è¯¯ï¼š{item['error']}\n"
            not_found_output += "\n"
    else:
        not_found_output += "âœ… æ‰€æœ‰æ–‡çŒ®éƒ½åœ¨arXivä¸­æ‰¾åˆ°äº†"
    
    return found_output, not_found_output

def format_verification_results(results):
    """æ ¼å¼åŒ–éªŒè¯ç»“æœ"""
    if 'error' in results:
        return f"âŒ é”™è¯¯: {results['error']}", f"âŒ é”™è¯¯: {results['error']}"
    
    if not results.get('verification_results'):
        return "âš ï¸ æœªè¿›è¡Œç›¸å…³æ€§éªŒè¯", "âš ï¸ æœªè¿›è¡Œç›¸å…³æ€§éªŒè¯"
    
    verified_correct = []
    verified_incorrect = []
    
    for result in results['verification_results']:
        if result['status'] == 'verified':
            citation_str = str(result['citation'])
            if '<æ˜¯>' in result.get('result', ''):
                verified_correct.append(citation_str)
            elif 'å¦' in result.get('result', ''):
                ai_result = result.get('result', '')
                reason = ai_result.replace('<å¦:', '').replace('>', '').strip()
                
                # è·å–æ–‡çŒ®æ ‡é¢˜
                citation_titles = []
                for cite_num in result['citation']:
                    if 1 <= cite_num <= len(results['titles']):
                        citation_titles.append(results['titles'][cite_num-1])
                
                verified_incorrect.append({
                    'citation': citation_str,
                    'titles': citation_titles,
                    'reason': reason
                })
    
    # æ ¼å¼åŒ–æŸ¥éªŒæ— è¯¯çš„ç»“æœ
    correct_output = "âœ… **æŸ¥éªŒæ— è¯¯çš„æ–‡çŒ®ï¼š**\n\n"
    if verified_correct:
        correct_output += f"å…± {len(verified_correct)} ä¸ªå¼•ç”¨æŸ¥éªŒæ— è¯¯ï¼š\n"
        for citation in verified_correct:
            correct_output += f"- å¼•ç”¨ {citation}\n"
    else:
        correct_output += "âš ï¸ æ²¡æœ‰æŸ¥éªŒæ— è¯¯çš„å¼•ç”¨"
    
    # æ ¼å¼åŒ–éœ€è¦æ£€æŸ¥çš„ç»“æœ
    incorrect_output = "âš ï¸ **ç›¸å…³æ€§ä½ï¼Œéœ€é‡ç‚¹æ£€æŸ¥çš„æ–‡çŒ®ï¼š**\n\n"
    if verified_incorrect:
        incorrect_output += f"å…± {len(verified_incorrect)} ä¸ªå¼•ç”¨éœ€è¦é‡ç‚¹æ£€æŸ¥ï¼š\n\n"
        for i, item in enumerate(verified_incorrect, 1):
            incorrect_output += f"**{i}. å¼•ç”¨ {item['citation']}**\n"
            if item['titles']:
                incorrect_output += f"   - æ ‡é¢˜ï¼š{'; '.join(item['titles'])}\n"
            incorrect_output += f"   - ç†ç”±ï¼š{item['reason']}\n\n"
    else:
        incorrect_output += "âœ… æ‰€æœ‰éªŒè¯çš„å¼•ç”¨éƒ½ç›¸å…³æ€§è‰¯å¥½"
    
    return correct_output, incorrect_output

def process_document(file, lightweight, skip_download, pdf_verify):
    """å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£ï¼Œå¸¦å®æ—¶æ—¥å¿—æ›´æ–°"""
    if file is None:
        yield "è¯·å…ˆä¸Šä¼ æ–‡æ¡£", "", "", "", "", "", ""
        return
    
    try:
        # ä½¿ç”¨å¸¦æ—¥å¿—çš„åˆ†æå‡½æ•°
        for result in verify_citations_and_analyze_with_logs(file.name, lightweight, skip_download, pdf_verify):
            if len(result) == 6:  # ä¸­é—´ç»“æœ
                logs, citation, arxiv_found, arxiv_not_found, verified_correct, status = result
                yield logs, citation, arxiv_found, arxiv_not_found, verified_correct, "", status
            elif len(result) == 7:  # æœ€ç»ˆç»“æœ
                logs, citation, arxiv_found, arxiv_not_found, verified_correct, verified_incorrect, status = result
                yield logs, citation, arxiv_found, arxiv_not_found, verified_correct, verified_incorrect, status
        
    except Exception as e:
        error_msg = f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        yield f"[{time.strftime('%H:%M:%S')}] {error_msg}", error_msg, "", "", "", "", error_msg

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(
        title="æ–‡çŒ®å¼•ç”¨æ£€æŸ¥å·¥å…·",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="sky",
            neutral_hue="slate",
        )
    ) as demo:
        
        gr.Markdown("""
        # ğŸ“š æ–‡çŒ®å¼•ç”¨æ£€æŸ¥å·¥å…·
        
        **åŠŸèƒ½ç®€ä»‹ï¼š** ä¸Šä¼ PDFæˆ–DOCXæ–‡æ¡£ï¼Œè‡ªåŠ¨æ£€æŸ¥æ–‡çŒ®å¼•ç”¨çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
        
        **ä¸»è¦ç‰¹æ€§ï¼š**
        - âœ… è‡ªåŠ¨æå–å‚è€ƒæ–‡çŒ®å’Œå¼•ç”¨æ ‡è®°
        - ğŸ” åœ¨arXivæ•°æ®åº“ä¸­æœç´¢åŒ¹é…æ–‡çŒ®
        - ğŸ¤– AIæ™ºèƒ½éªŒè¯å¼•ç”¨ç›¸å…³æ€§
        - ğŸ“Š è¯¦ç»†çš„ç»Ÿè®¡åˆ†ææŠ¥å‘Š
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ æ–‡æ¡£ä¸Šä¼ ")
                file_input = gr.File(
                    label="é€‰æ‹©PDFæˆ–DOCXæ–‡ä»¶",
                    file_types=[".pdf", ".docx"],
                    type="filepath"
                )
                
                gr.Markdown("### âš™ï¸ æ£€æŸ¥é€‰é¡¹")
                lightweight_mode = gr.Checkbox(
                    label="è½»é‡çº§æ¨¡å¼",
                    value=True,
                    info="ä½¿ç”¨arXivå…ƒæ•°æ®éªŒè¯ï¼Œæ›´å¿«é€Ÿ"
                )
                skip_download = gr.Checkbox(
                    label="è·³è¿‡PDFä¸‹è½½",
                    value=True,
                    info="ä¸ä¸‹è½½PDFæ–‡ä»¶åˆ°æœ¬åœ°"
                )
                pdf_verify = gr.Checkbox(
                    label="PDFéªŒè¯",
                    value=False,
                    info="ä½¿ç”¨æœ¬åœ°PDFè¿›è¡Œæ·±åº¦éªŒè¯"
                )
                
                process_btn = gr.Button(
                    "ğŸš€ å¼€å§‹æ£€æŸ¥",
                    variant="primary",
                    size="lg"
                )
                
                status = gr.Textbox(
                    label="çŠ¶æ€",
                    value="ç­‰å¾…ä¸Šä¼ æ–‡æ¡£...",
                    interactive=False
                )
            
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“œ å®æ—¶æ—¥å¿—")
                logs = gr.Textbox(
                    label="å¤„ç†æ—¥å¿—",
                    lines=15,
                    max_lines=20,
                    interactive=False,
                    autoscroll=True,
                    placeholder="æ—¥å¿—å°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                )
                
                clear_logs_btn = gr.Button(
                    "ğŸ—‘ï¸ æ¸…é™¤æ—¥å¿—",
                    variant="secondary",
                    size="sm"
                )
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“Š å¼•æ–‡ç»Ÿè®¡åˆ†æ")
                citation_analysis = gr.Textbox(
                    label="å¼•æ–‡æ•°é‡åˆ†æ",
                    lines=10,
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“š arXivæ–‡çŒ®æ£€ç´¢ç»“æœ")
                arxiv_found = gr.Textbox(
                    label="arXivä¸­å¯ä»¥æ‰¾åˆ°çš„æ–‡çŒ®",
                    lines=8,
                    interactive=False
                )
            
            with gr.Column():
                arxiv_not_found = gr.Textbox(
                    label="arXivä¸­ä¸å¯ä»¥æ‰¾åˆ°çš„æ–‡çŒ®",
                    lines=8,
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### âœ… ç›¸å…³æ€§éªŒè¯ç»“æœ")
                verified_correct = gr.Textbox(
                    label="æŸ¥éªŒæ— è¯¯",
                    lines=6,
                    interactive=False
                )
            
            with gr.Column():
                verified_incorrect = gr.Textbox(
                    label="ç›¸å…³æ€§ä½ï¼Œéœ€é‡ç‚¹æ£€æŸ¥",
                    lines=6,
                    interactive=False
                )
        
        # äº‹ä»¶ç»‘å®š
        process_btn.click(
            fn=process_document,
            inputs=[file_input, lightweight_mode, skip_download, pdf_verify],
            outputs=[logs, citation_analysis, arxiv_found, arxiv_not_found, verified_correct, verified_incorrect, status]
        )
        
        # æ¸…é™¤æ—¥å¿—äº‹ä»¶
        clear_logs_btn.click(
            fn=lambda: "",
            outputs=logs
        )
        
        gr.Markdown("""
        ---
        **ä½¿ç”¨è¯´æ˜ï¼š**
        1. ä¸Šä¼ PDFæˆ–DOCXæ ¼å¼çš„å­¦æœ¯æ–‡æ¡£
        2. é€‰æ‹©åˆé€‚çš„æ£€æŸ¥æ¨¡å¼ï¼ˆæ¨èä½¿ç”¨è½»é‡çº§æ¨¡å¼ï¼‰
        3. ç‚¹å‡»"å¼€å§‹æ£€æŸ¥"æŒ‰é’®è¿›è¡Œåˆ†æ
        4. æŸ¥çœ‹è¯¦ç»†çš„åˆ†æç»“æœå’Œå»ºè®®
        
        **æ³¨æ„äº‹é¡¹ï¼š**
        - éœ€è¦è®¾ç½®ZHIPUAI_API_KEYç¯å¢ƒå˜é‡
        - è½»é‡çº§æ¨¡å¼é€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆå¿«é€Ÿæ£€æŸ¥
        """)
    
    return demo

if __name__ == "__main__":
    # æ£€æŸ¥API key
    if not os.environ.get("ZHIPUAI_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½®ZHIPUAI_API_KEYç¯å¢ƒå˜é‡")
        exit(1)
    
    # å¯åŠ¨ç•Œé¢
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )


